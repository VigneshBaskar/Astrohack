{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"../Pre_processing\")\n",
    "\n",
    "from Data_Preparation_Library import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "image_size=128\n",
    "maxBatchId = 24\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selectedBatches=[\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\"]\n",
    "selectedBatches=[str(i) for i in range(maxBatchId)]\n",
    "\n",
    "extra_folder=str(image_size)+\"_\"+str(image_size)\n",
    "batch_data_object = []\n",
    "for i in selectedBatches:\n",
    "    with open(os.path.join(temp_path,extra_folder,'full_data_object_' + i + '.p'), 'rb') as handle:\n",
    "        batch_data_object+=pickle.load(handle)\n",
    "\n",
    "data_train = batch_data_object[0:int(len(batch_data_object)*2/3)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_data_test_object = []\n",
    "for i in range(8):\n",
    "    with open(os.path.join(temp_path,extra_folder,'test_data_object_' + str(i) + '.p'), 'rb') as handle:\n",
    "        batch_data_test_object+=pickle.load(handle)\n",
    "        \n",
    "data_test  = batch_data_test_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flux(d):\n",
    "  # TODO: get flux_i from model\n",
    "    #if d.i_image != None:\n",
    "    #    flux_i = sum(sum(d.i_image))\n",
    "    #else:\n",
    "    #    flux_i = 0\n",
    "    flux_g = sum(sum(d.g_image_resized))\n",
    "    #return flux_i+flux_g, flux_g-flux_i\n",
    "    return flux_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.core import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8447, (128, 128, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_data_test_object),batch_data_test_object[0].g_image_resized_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "version=\"v1\"\n",
    "res_folder=\"results_\"+str(image_size)+\"_on_\"+str(image_size)\n",
    "with open(os.path.join(os.path.join(output_path,res_folder),\"encoder_results_train_\"+version+\"__all\"),'rb') as handle:\n",
    "    encoded_imgs1=pickle.load(handle)\n",
    "    encoded_imgs_reshaped_train = [e.reshape(-1,1) for e in encoded_imgs1]\n",
    "\n",
    "model_encoder=load_model(os.path.join(os.path.join(output_path,res_folder),\"encoder_model_\"+version+\"__all\"))\n",
    "\n",
    "def get_g_Data_for_Autoencoder(data_object):\n",
    "    X_list=[(data_object[index].g_image_resized_reshaped)/data_object[index].g_image_resized_reshaped.max() for index in range(len(data_object))]\n",
    "    return np.asarray(X_list),np.asarray(X_list)\n",
    "\n",
    "X_test_auto_encoder,y_test_auto_encoder=get_g_Data_for_Autoencoder(batch_data_test_object)\n",
    "\n",
    "encoded_imgs2=model_encoder.predict(X_test_auto_encoder)\n",
    "encoded_imgs_reshaped_test = [e.reshape(-1,1) for e in encoded_imgs2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15769, 4101) (15769,)\n"
     ]
    }
   ],
   "source": [
    "# accessible in the class: size of image, maximum of image, normalization factor of g + fitted value of normalization factor for i\n",
    "# define a function to get the training and testing dataset\n",
    "\n",
    "def obtain_train_data():\n",
    "    train_features = []\n",
    "    train_labels = []\n",
    "    for i in range(len(data_train)):\n",
    "        if data_train[i].logMstar!=-99:\n",
    "            e = encoded_imgs_reshaped_train[i]\n",
    "            d = data_train[i]\n",
    "            #f1,f2 = flux(d)\n",
    "            f = flux(d)\n",
    "            size_1=d.g_image.shape[0]\n",
    "            size_2=d.g_image.shape[1]\n",
    "            img_max=d.g_image.max()\n",
    "            dist=d.Distance\n",
    "            train_features.append(np.append(e,np.array([f,size_1,size_2,img_max,dist])))\n",
    "            #train_features.append(np.append(e,np.array([f])))\n",
    "            train_labels.append(d.logMstar)\n",
    "    return train_features, train_labels\n",
    "\n",
    "train_features = np.asarray(obtain_train_data()[0])\n",
    "train_labels = np.asarray(obtain_train_data()[1])\n",
    "\n",
    "print(train_features.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15769,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels=np.exp(train_labels)\n",
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8447, 4101) (8447,)\n"
     ]
    }
   ],
   "source": [
    "def obtain_test_data():\n",
    "    test_features = []\n",
    "    test_labels = []\n",
    "    for j in range(len(data_test)):\n",
    "        if data_test[j].logMstar!=-99:\n",
    "            e = encoded_imgs_reshaped_test[j]\n",
    "            d = data_test[j]\n",
    "\n",
    "        #f1,f2 = flux(d)\n",
    "            f = flux(d)\n",
    "            size_1=d.g_image.shape[0]\n",
    "            size_2=d.g_image.shape[1]\n",
    "            img_max=d.g_image.max()\n",
    "            dist=d.Distance\n",
    "            test_features.append(np.append(e,np.array([f,size_1,size_2,img_max,dist])))\n",
    "            test_labels.append(d.logMstar)\n",
    "\n",
    "    return test_features, test_labels\n",
    "\n",
    "test_features = np.asarray(obtain_test_data()[0])\n",
    "test_labels = np.asarray(obtain_test_data()[1])\n",
    "\n",
    "print(test_features.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # ## transform features\n",
    "# # train_features = StandardScaler().fit_transform(train_features)\n",
    "# # test_features = StandardScaler().transform(test_features)\n",
    "# # #features = MinMaxScaler().fit_transform(features)\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "train_features = X_scaler.fit_transform(train_features)\n",
    "test_features = X_scaler.transform(test_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_features=train_features/(train_features.max(0).T)\n",
    "# test_features=test_features/(train_features.max(0).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.core import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(32, activation='relu', input_dim=train_features.shape[1]))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1,activation=\"relu\"))\n",
    "model.compile(optimizer='Adadelta',\n",
    "              loss='mse',\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15769 samples, validate on 8447 samples\n",
      "Epoch 1/40\n",
      "15769/15769 [==============================] - 2s - loss: 1541778950.2502 - mean_squared_error: 1541778950.2502 - val_loss: 1499610422.4004 - val_mean_squared_error: 1499610422.4004\n",
      "Epoch 2/40\n",
      "15769/15769 [==============================] - 1s - loss: 800523185.0441 - mean_squared_error: 800523185.0441 - val_loss: 1740880255.2878 - val_mean_squared_error: 1740880255.2878\n",
      "Epoch 3/40\n",
      "15769/15769 [==============================] - 1s - loss: 711872746.9075 - mean_squared_error: 711872746.9075 - val_loss: 1842958789.4779 - val_mean_squared_error: 1842958789.4779\n",
      "Epoch 4/40\n",
      "15769/15769 [==============================] - 1s - loss: 685697759.2999 - mean_squared_error: 685697759.2999 - val_loss: 1877513173.8738 - val_mean_squared_error: 1877513173.8738\n",
      "Epoch 5/40\n",
      "15769/15769 [==============================] - 1s - loss: 682219534.3228 - mean_squared_error: 682219534.3228 - val_loss: 1899530982.4818 - val_mean_squared_error: 1899530982.4818\n",
      "Epoch 6/40\n",
      "15769/15769 [==============================] - 1s - loss: 667463101.7718 - mean_squared_error: 667463101.7718 - val_loss: 1908650002.0627 - val_mean_squared_error: 1908650002.0627\n",
      "Epoch 7/40\n",
      "15769/15769 [==============================] - 1s - loss: 671360896.9578 - mean_squared_error: 671360896.9578 - val_loss: 1916393325.3766 - val_mean_squared_error: 1916393325.3766\n",
      "Epoch 8/40\n",
      "15769/15769 [==============================] - 1s - loss: 657291405.8966 - mean_squared_error: 657291405.8966 - val_loss: 1922115588.1520 - val_mean_squared_error: 1922115588.1520\n",
      "Epoch 9/40\n",
      "15769/15769 [==============================] - 1s - loss: 657368156.4223 - mean_squared_error: 657368156.4223 - val_loss: 1928538550.3549 - val_mean_squared_error: 1928538550.3549\n",
      "Epoch 10/40\n",
      "15769/15769 [==============================] - 1s - loss: 650947332.4705 - mean_squared_error: 650947332.4705 - val_loss: 1931819811.1254 - val_mean_squared_error: 1931819811.1254\n",
      "Epoch 11/40\n",
      "15769/15769 [==============================] - 1s - loss: 648937697.1912 - mean_squared_error: 648937697.1912 - val_loss: 1942482784.1932 - val_mean_squared_error: 1942482784.1932\n",
      "Epoch 12/40\n",
      "15769/15769 [==============================] - 1s - loss: 651000524.9794 - mean_squared_error: 651000524.9794 - val_loss: 1948068872.9708 - val_mean_squared_error: 1948068872.9708\n",
      "Epoch 13/40\n",
      "15769/15769 [==============================] - 1s - loss: 643147642.8334 - mean_squared_error: 643147642.8334 - val_loss: 1954271120.4716 - val_mean_squared_error: 1954271120.4716\n",
      "Epoch 14/40\n",
      "15769/15769 [==============================] - 1s - loss: 643063485.2828 - mean_squared_error: 643063485.2828 - val_loss: 1957564185.0030 - val_mean_squared_error: 1957564185.0030\n",
      "Epoch 15/40\n",
      "15769/15769 [==============================] - 1s - loss: 638089859.6609 - mean_squared_error: 638089859.6609 - val_loss: 1958975834.9502 - val_mean_squared_error: 1958975834.9502\n",
      "Epoch 16/40\n",
      "15769/15769 [==============================] - 1s - loss: 628910139.9800 - mean_squared_error: 628910139.9800 - val_loss: 1961032019.1311 - val_mean_squared_error: 1961032019.1311\n",
      "Epoch 17/40\n",
      "15769/15769 [==============================] - 1s - loss: 624962176.7793 - mean_squared_error: 624962176.7793 - val_loss: 1966890479.9072 - val_mean_squared_error: 1966890479.9072\n",
      "Epoch 18/40\n",
      "15769/15769 [==============================] - 1s - loss: 626415519.6246 - mean_squared_error: 626415519.6246 - val_loss: 1971925815.1884 - val_mean_squared_error: 1971925815.1884\n",
      "Epoch 19/40\n",
      "15769/15769 [==============================] - 1s - loss: 619142585.1856 - mean_squared_error: 619142585.1856 - val_loss: 1972288002.3033 - val_mean_squared_error: 1972288002.3033\n",
      "Epoch 20/40\n",
      "15769/15769 [==============================] - 1s - loss: 625731551.9046 - mean_squared_error: 625731551.9046 - val_loss: 1980429965.8350 - val_mean_squared_error: 1980429965.8350\n",
      "Epoch 21/40\n",
      "15769/15769 [==============================] - 1s - loss: 610912801.7513 - mean_squared_error: 610912801.7513 - val_loss: 1982882623.0075 - val_mean_squared_error: 1982882623.0075\n",
      "Epoch 22/40\n",
      "15769/15769 [==============================] - 1s - loss: 613552322.0780 - mean_squared_error: 613552322.0780 - val_loss: 1983304504.1582 - val_mean_squared_error: 1983304504.1582\n",
      "Epoch 23/40\n",
      "15769/15769 [==============================] - 1s - loss: 607318934.2046 - mean_squared_error: 607318934.2046 - val_loss: 1991730580.5630 - val_mean_squared_error: 1991730580.5630\n",
      "Epoch 24/40\n",
      "15769/15769 [==============================] - 1s - loss: 607224853.1493 - mean_squared_error: 607224853.1493 - val_loss: 1990534289.2293 - val_mean_squared_error: 1990534289.2293\n",
      "Epoch 25/40\n",
      "15769/15769 [==============================] - 1s - loss: 595253021.2057 - mean_squared_error: 595253021.2057 - val_loss: 1993799486.5226 - val_mean_squared_error: 1993799486.5226\n",
      "Epoch 26/40\n",
      "15769/15769 [==============================] - 1s - loss: 590934174.4679 - mean_squared_error: 590934174.4679 - val_loss: 1997057846.5216 - val_mean_squared_error: 1997057846.5216\n",
      "Epoch 27/40\n",
      "15769/15769 [==============================] - 1s - loss: 598266552.5200 - mean_squared_error: 598266552.5200 - val_loss: 2005863455.3370 - val_mean_squared_error: 2005863455.3370\n",
      "Epoch 28/40\n",
      "15769/15769 [==============================] - 1s - loss: 586973439.3466 - mean_squared_error: 586973439.3466 - val_loss: 2005060672.8562 - val_mean_squared_error: 2005060672.8562\n",
      "Epoch 29/40\n",
      "15769/15769 [==============================] - 1s - loss: 591592291.9876 - mean_squared_error: 591592291.9876 - val_loss: 2012063823.6155 - val_mean_squared_error: 2012063823.6155\n",
      "Epoch 30/40\n",
      "15769/15769 [==============================] - 1s - loss: 585025586.2617 - mean_squared_error: 585025586.2617 - val_loss: 2010357378.1366 - val_mean_squared_error: 2010357378.1366\n",
      "Epoch 31/40\n",
      "15769/15769 [==============================] - 1s - loss: 586093295.9645 - mean_squared_error: 586093295.9645 - val_loss: 2018796797.6058 - val_mean_squared_error: 2018796797.6058\n",
      "Epoch 32/40\n",
      "15769/15769 [==============================] - 1s - loss: 585516088.6093 - mean_squared_error: 585516088.6093 - val_loss: 2018520772.5384 - val_mean_squared_error: 2018520772.5384\n",
      "Epoch 33/40\n",
      "15769/15769 [==============================] - 1s - loss: 576118371.4194 - mean_squared_error: 576118371.4194 - val_loss: 2017815052.3954 - val_mean_squared_error: 2017815052.3954\n",
      "Epoch 34/40\n",
      "15769/15769 [==============================] - 1s - loss: 570661421.2716 - mean_squared_error: 570661421.2716 - val_loss: 2015205569.6593 - val_mean_squared_error: 2015205569.6593\n",
      "Epoch 35/40\n",
      "15769/15769 [==============================] - 1s - loss: 568236000.5581 - mean_squared_error: 568236000.5581 - val_loss: 2027040543.5492 - val_mean_squared_error: 2027040543.5492\n",
      "Epoch 36/40\n",
      "15769/15769 [==============================] - 1s - loss: 567021990.7677 - mean_squared_error: 567021990.7677 - val_loss: 2032748106.9786 - val_mean_squared_error: 2032748106.9786\n",
      "Epoch 37/40\n",
      "15769/15769 [==============================] - 1s - loss: 571062934.2553 - mean_squared_error: 571062934.2553 - val_loss: 2033944513.8108 - val_mean_squared_error: 2033944513.8108\n",
      "Epoch 38/40\n",
      "15769/15769 [==============================] - 1s - loss: 559838243.3504 - mean_squared_error: 559838243.3504 - val_loss: 2031580026.4084 - val_mean_squared_error: 2031580026.4084\n",
      "Epoch 39/40\n",
      "15769/15769 [==============================] - 1s - loss: 560921918.7824 - mean_squared_error: 560921918.7824 - val_loss: 2035057708.1264 - val_mean_squared_error: 2035057708.1264\n",
      "Epoch 40/40\n",
      "15769/15769 [==============================] - 1s - loss: 560237250.4392 - mean_squared_error: 560237250.4392 - val_loss: 2035033894.4591 - val_mean_squared_error: 2035033894.4591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b1e57150400>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_features, train_labels, epochs=40, batch_size=32,shuffle=True,\n",
    "                validation_data=(test_features, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8447\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "test_predict = []\n",
    "test_data_sdss_id=[]\n",
    "for i in range(len(batch_data_test_object)):\n",
    "\n",
    "    test_predict.append(model.predict(test_features[i].reshape(1,-1))[0][0])\n",
    "    test_data_sdss_id.append(batch_data_test_object[i].SDSS_ID)\n",
    "    \n",
    "print(len(test_predict))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame({\"pssid\":test_data_sdss_id,\"mass\":np.log(test_predict)})\n",
    "df\n",
    "df[[\"pssid\",\"mass\"]].to_csv(os.path.join(output_path,\"sub_\"+version+\"_\"+str(image_size)+\"_4.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mass</th>\n",
       "      <th>pssid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.823605</td>\n",
       "      <td>1237662302977851635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.573089</td>\n",
       "      <td>1237652899687104664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.758847</td>\n",
       "      <td>1237649954407907520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.939822</td>\n",
       "      <td>1237661055281856813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.915992</td>\n",
       "      <td>1237651272957689913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.519296</td>\n",
       "      <td>1237651755075174608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.454989</td>\n",
       "      <td>1237654383051014364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.609559</td>\n",
       "      <td>1237653614261043391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.601315</td>\n",
       "      <td>1237654604785189128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.434722</td>\n",
       "      <td>1237663546368721125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.700471</td>\n",
       "      <td>1237662238011097189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.062015</td>\n",
       "      <td>1237665531712372935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.911983</td>\n",
       "      <td>1237662198824239593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10.545770</td>\n",
       "      <td>1237648702992023572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.087232</td>\n",
       "      <td>1237652936183775521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10.959231</td>\n",
       "      <td>1237652934036357428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10.807476</td>\n",
       "      <td>1237655502421033116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10.035486</td>\n",
       "      <td>1237679434525114569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9.742671</td>\n",
       "      <td>1237652901828427877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10.021703</td>\n",
       "      <td>1237657629528358993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-inf</td>\n",
       "      <td>1237655369824731360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10.516484</td>\n",
       "      <td>1237667253461123297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10.725286</td>\n",
       "      <td>1237652629633368214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10.471440</td>\n",
       "      <td>1237652899688939737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10.447678</td>\n",
       "      <td>1237652600108155080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10.481844</td>\n",
       "      <td>1237667536939319414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10.439944</td>\n",
       "      <td>1237668496314990745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10.461553</td>\n",
       "      <td>1237648722827870284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10.379147</td>\n",
       "      <td>1237651735780917709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10.791292</td>\n",
       "      <td>1237648722837307771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8417</th>\n",
       "      <td>10.943188</td>\n",
       "      <td>1237661463841341823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8418</th>\n",
       "      <td>10.727280</td>\n",
       "      <td>1237662619723235396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8419</th>\n",
       "      <td>11.071326</td>\n",
       "      <td>1237664671640911986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8420</th>\n",
       "      <td>10.718493</td>\n",
       "      <td>1237660765916299353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8421</th>\n",
       "      <td>10.122395</td>\n",
       "      <td>1237653587942768998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8422</th>\n",
       "      <td>10.775790</td>\n",
       "      <td>1237662501080596510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8423</th>\n",
       "      <td>10.977951</td>\n",
       "      <td>1237657775541977310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8424</th>\n",
       "      <td>11.001737</td>\n",
       "      <td>1237657401343279284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8425</th>\n",
       "      <td>10.894301</td>\n",
       "      <td>1237673703971422345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8426</th>\n",
       "      <td>10.232327</td>\n",
       "      <td>1237655347821347286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8427</th>\n",
       "      <td>10.970171</td>\n",
       "      <td>1237657769629646912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8428</th>\n",
       "      <td>10.340364</td>\n",
       "      <td>1237661852000714842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8429</th>\n",
       "      <td>10.964055</td>\n",
       "      <td>1237654390569828388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8430</th>\n",
       "      <td>10.661831</td>\n",
       "      <td>1237661357002981504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8431</th>\n",
       "      <td>10.596727</td>\n",
       "      <td>1237657634334507359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8432</th>\n",
       "      <td>11.031680</td>\n",
       "      <td>1237661358081507332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8433</th>\n",
       "      <td>10.995216</td>\n",
       "      <td>1237661150843240530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8434</th>\n",
       "      <td>10.324284</td>\n",
       "      <td>1237657634335358986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8435</th>\n",
       "      <td>10.970254</td>\n",
       "      <td>1237657770170908761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8436</th>\n",
       "      <td>10.719392</td>\n",
       "      <td>1237663547437351232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8437</th>\n",
       "      <td>11.049265</td>\n",
       "      <td>1237653613720043711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8438</th>\n",
       "      <td>10.862720</td>\n",
       "      <td>1237657856606929042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8439</th>\n",
       "      <td>11.141274</td>\n",
       "      <td>1237651191895556239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8440</th>\n",
       "      <td>11.111482</td>\n",
       "      <td>1237655464315650214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8441</th>\n",
       "      <td>11.123271</td>\n",
       "      <td>1237653613722402918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8442</th>\n",
       "      <td>10.951218</td>\n",
       "      <td>1237653614259142866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8443</th>\n",
       "      <td>10.983954</td>\n",
       "      <td>1237655464849637540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8444</th>\n",
       "      <td>10.329049</td>\n",
       "      <td>1237655109451055189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8445</th>\n",
       "      <td>11.104925</td>\n",
       "      <td>1237661353779921076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8446</th>\n",
       "      <td>10.601050</td>\n",
       "      <td>1237651225171329101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8447 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           mass                pssid\n",
       "0     10.823605  1237662302977851635\n",
       "1     10.573089  1237652899687104664\n",
       "2     10.758847  1237649954407907520\n",
       "3     10.939822  1237661055281856813\n",
       "4     10.915992  1237651272957689913\n",
       "5     10.519296  1237651755075174608\n",
       "6     10.454989  1237654383051014364\n",
       "7     10.609559  1237653614261043391\n",
       "8     10.601315  1237654604785189128\n",
       "9     10.434722  1237663546368721125\n",
       "10    10.700471  1237662238011097189\n",
       "11    10.062015  1237665531712372935\n",
       "12    10.911983  1237662198824239593\n",
       "13    10.545770  1237648702992023572\n",
       "14    10.087232  1237652936183775521\n",
       "15    10.959231  1237652934036357428\n",
       "16    10.807476  1237655502421033116\n",
       "17    10.035486  1237679434525114569\n",
       "18     9.742671  1237652901828427877\n",
       "19    10.021703  1237657629528358993\n",
       "20         -inf  1237655369824731360\n",
       "21    10.516484  1237667253461123297\n",
       "22    10.725286  1237652629633368214\n",
       "23    10.471440  1237652899688939737\n",
       "24    10.447678  1237652600108155080\n",
       "25    10.481844  1237667536939319414\n",
       "26    10.439944  1237668496314990745\n",
       "27    10.461553  1237648722827870284\n",
       "28    10.379147  1237651735780917709\n",
       "29    10.791292  1237648722837307771\n",
       "...         ...                  ...\n",
       "8417  10.943188  1237661463841341823\n",
       "8418  10.727280  1237662619723235396\n",
       "8419  11.071326  1237664671640911986\n",
       "8420  10.718493  1237660765916299353\n",
       "8421  10.122395  1237653587942768998\n",
       "8422  10.775790  1237662501080596510\n",
       "8423  10.977951  1237657775541977310\n",
       "8424  11.001737  1237657401343279284\n",
       "8425  10.894301  1237673703971422345\n",
       "8426  10.232327  1237655347821347286\n",
       "8427  10.970171  1237657769629646912\n",
       "8428  10.340364  1237661852000714842\n",
       "8429  10.964055  1237654390569828388\n",
       "8430  10.661831  1237661357002981504\n",
       "8431  10.596727  1237657634334507359\n",
       "8432  11.031680  1237661358081507332\n",
       "8433  10.995216  1237661150843240530\n",
       "8434  10.324284  1237657634335358986\n",
       "8435  10.970254  1237657770170908761\n",
       "8436  10.719392  1237663547437351232\n",
       "8437  11.049265  1237653613720043711\n",
       "8438  10.862720  1237657856606929042\n",
       "8439  11.141274  1237651191895556239\n",
       "8440  11.111482  1237655464315650214\n",
       "8441  11.123271  1237653613722402918\n",
       "8442  10.951218  1237653614259142866\n",
       "8443  10.983954  1237655464849637540\n",
       "8444  10.329049  1237655109451055189\n",
       "8445  11.104925  1237661353779921076\n",
       "8446  10.601050  1237651225171329101\n",
       "\n",
       "[8447 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
